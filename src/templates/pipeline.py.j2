'''
Jinja template for pipeline creation.
'''

from datetime import datetime

import kfp
from kfp import dsl

from container_wrapper import ContainerWrapper as Container
from s3_utils import S3Utils


# - ***Variables for user project*** - #
PROJECT_NAME = '{{ pipeline.pipelineName }}'

{% for env_var in pipeline.defaultParams.envVars %}
{{ env_var.key }} = '{{ env_var.value }}'
{% endfor %}

BUCKET_NAME_VAR = S3Utils.replace_invalid_bucket_name_chars('{{ pipeline.defaultParams.storageBucket }}')
BUCKET_PATH = ''

def create_container(**kwargs):
    '''
    Wraps container with env vars, forwards env vars with kwargs.
    '''

    return Container(
        setup_command='{{ pipeline.defaultParams.setupCommand }}',
        verbose=True,
        {% for env_var in pipeline.defaultParams.envVars %}
        {{ env_var.key }} = '{{ env_var.value }}',
        {% endfor %}
        BUCKET_NAME=BUCKET_NAME_VAR,
        BUCKET_PATH=BUCKET_PATH,
        **kwargs
    )


# TODO: Currentrly this uses only S3, must be adapted for later use with various types (create a masterClass)
def setup_storage_pipeline_dependencies(files=[]):
    '''
    Manually sets up the s3 objects for the first container.
    '''

    local_files = [
        file['key'] for file in files if file['value'] == 'local'
    ]

    s3 = S3Utils(
        S3_ENDPOINT,
        S3_ACCESS_KEY,
        S3_SECRET_KEY,
        bucket_name=BUCKET_NAME_VAR,
        bucket_path=BUCKET_PATH
    )

    s3.upload(local_files)

    # TODO: still needs to treat other file sources -> can even be user defined


# - ***USER DEFINED PIPELINE*** - #

# Generate funcions
{% for step in pipeline.pipelineSteps %}
def {{ make_step_function_name(step.name) }}():
    container = create_container(
    {% for env_var in step.envVars %}
        {{ env_var.key }}='{{ env_var.value }}',
    {% endfor %}
    )
    container.name = '{{ step.name }}'

    container.file_inputs = [
    {% for file in step.fileInputs %}
        '{{ file }}',
    {% endfor %}
    {% for file in pipeline.defaultParams.globalFiles %}
        '{{ file }}',
    {% endfor %}
    ]

    container.file_outputs = [
    {% for file in step.fileOutputs %}
        '{{ file }}',
    {% endfor %}
    ]

    return container.run('{{step.entrypoint}}')
{% endfor %}


@dsl.pipeline(
    name='{{ pipeline.pipelineName }}',
    description='{{ pipeline.description }}'
)
def {{ make_pipeline_function_name(pipeline.pipelineName) }}():

    {% for step in pipeline.pipelineSteps %}
    {{ make_step_function_pointer_name(step.name) }} = {{ make_step_function_name(step.name) }}()
        {% if step.runAfter %}
    {{ make_step_function_pointer_name(step.name) }}.after({{ make_step_function_pointer_name(step.runAfter) }})
        {% endif %}
    {% endfor %}


# falta montar a main certa
if __name__ == '__main__':
    # TODO: colocar algum tipo de if aqui, q usa sys.args, e a gnt passa na hr de compilar, se entrar no if, sobe os arquivos e o pipe, cria a run e bora

    PROJECT_NAME = S3Utils.replace_invalid_bucket_name_chars(PROJECT_NAME)

    # hash = uuid.uuid4()  # o proprio marvin passa o hash pro arquivo final -> template recebe o hash
    # TODO: s√≥ entra aqui SE tiver especificado que vai criar run?
    global HASH_
    HASH_ = '{{ pipeline.uuid }}'
    date_str = datetime.now().strftime('%Y-%m-%d')

    global BUCKET_PATH_
    BUCKET_PATH_ = f'{PROJECT_NAME}-{date_str}-{HASH_}'

    pipeline_file_path = f'{PROJECT_NAME}.yaml'

    {% if upload %}
    setup_storage_pipeline_dependencies(
        [
            {% for file_struct in defaultParams.dependencies %}
            {{ file_struct }},
            {% endfor %}
        ]
    )
    {% endif %}

    kfp.compiler.Compiler().compile({{ make_pipeline_function_name(pipeline.pipelineName) }}, pipeline_file_path)
    print(BUCKET_PATH_)


    {# # CERTO
    pipeline_file_path = 'pipelines.yaml' # extract it from your database
    pipeline_name = 'Your Pipeline Name'

    client = kfp.Client()
    pipeline = client.pipeline_uploads.upload_pipeline(pipeline_file_path, name=pipeline_name) #}
