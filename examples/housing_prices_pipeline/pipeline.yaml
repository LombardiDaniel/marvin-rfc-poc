pipelineName: pipeline_housing_prices
description: Pipeline for presentation of famous housing_prices problem

defaultParams:
    storageBucket: housing_prices
    setupCommand: pip install -r requirements.txt
    envVars:
        # KFP CONFIG:
        - KFP_ENDPOINT: kfp_uri
        # - KFP_CLIENT_ID: pegar computer name?
        # CLOUD STORAGE CONFIG:
        - S3_ACCESS_KEY: minio_key
        - S3_SECRET_KEY: $MINIO_SECRET_KEY  # Since this key starts with '$', it will be fetched from 'envFile'
        - S3_ENDPOINT: minio_uri
    dependencies:
        - requirements.txt: local  # default is local ~> means 'setup_kfp' command will upload FROM LOCAL MACHINE
        - test.csv
        - train.csv
        - acquisitor.py
        - data_prep.py
        - train_model.py
        - evaluate.py
    globalFiles:
        - requirements.txt
    envFile: .env
    image: python:3.7
    # gettings parameters from:
    # https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.client.html
    runParams:
        - enable_caching: true
    recurringRunParams:
        - cronExpression: 0-59/2 * * * *  # “At every 2nd minute from 0 through 59.”
        - max_concurrency: 2
        - no_catchup: true

pipelineSteps:
    - name: acquisitor
      description: Acquisitor
      entrypoint: python acquisitor.py
      GPUs:
        gpuLimit: 2  # optional
        nodeSelector:  # optional
            cloud.google.com/gke-accelerator: nvidia-tesla-p4
      envVars:
        - MY_ENV_VAR: test_specific_env
      fileInputs:
        - test.csv
        - train.csv
      image: python:3.8

    - name: data_prep
      description: Data preparator
      runAfter: acquisitor
      entrypoint: python data_prep.py
      TPUs:
        tpu_cores: 8
        tpu_resource: 'v2'
        tf_version: '1.12'
      fileInputs:
        - test.csv
        - train.csv
        - data_prep.py
      fileOutputs:
        - X_train.csv
        - y_train.csv
        - X_test.csv
        - y_test.csv

    - name: train_model
      description: Train the machine learning model
      runAfter: data_prep
      entrypoint: python train_model.py
      fileInputs:
        - X_train.csv
        - y_train.csv
        - X_test.csv
        - y_test.csv
        - train_model.py
      fileOutputs:
        - regressionTree
        - regressionLinear
        - randomForest

    - name: evaluate
      description: Evaluates the metrics
      runAfter: train_model
      entrypoint: python evaluate.py
      fileInputs:
        - X_train.csv
        - y_train.csv
        - X_test.csv
        - y_test.csv
        - regressionTree
        - regressionLinear
        - randomForest
        - evaluate.py
